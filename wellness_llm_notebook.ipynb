{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "8F3xVTTbsoCX"
      },
      "source": [
        "# WellnessGrid LLM Integration Notebook\n",
        "\n",
        "This notebook demonstrates the LLM functionality used in the WellnessGrid app using:\n",
        "- **BioGPT-Large** for text generation\n",
        "- **BioBERT** for embeddings\n",
        "- **Hugging Face Inference API**\n",
        "\n",
        "## Setup Instructions\n",
        "1. Run this notebook in Google Colab\n",
        "2. Set your Hugging Face API token in the first cell\n",
        "3. Execute cells in order to test the functionality\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "97xQThaysoCa"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install transformers flask flask-cors pyngrok --quiet\n",
        "!pip install sentence-transformers scikit-learn --quiet\n",
        "!pip install sacremoses --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Models"
      ],
      "metadata": {
        "id": "6-q-NKKhtYgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BioGPT-Large\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"microsoft/BioGPT-Large\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGQkAFxLszSy",
        "outputId": "db913082-a286-4715-83cb-eb9bf9570f30"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "8Gks2AfwyS0Y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "biobert = SentenceTransformer('pritamdeka/S-BioBert-snli-multinli-stsb', device=device)"
      ],
      "metadata": {
        "id": "8--dIof6x2Yt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Document Embeddings & Retriver"
      ],
      "metadata": {
        "id": "JtG1OmfszljK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = []\n",
        "doc_embedings = []"
      ],
      "metadata": {
        "id": "uFaTjEbTwKvT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_doc(text):\n",
        "    # Embed the incoming doc using BioBERT\n",
        "    embedding = biobert.encode([text], convert_to_tensor=True)[0].cpu().numpy()\n",
        "\n",
        "    # Store in memory\n",
        "    docs.append(text)\n",
        "    doc_embeddings.append(embedding)\n",
        "\n",
        "    print(f\"âœ… Added document. Total docs: {len(docs)}\")"
      ],
      "metadata": {
        "id": "smA7-I0X0UbL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_most_similar_doc(query, top_k=1):\n",
        "    if not doc_embeddings:\n",
        "        return \"âŒ No documents in memory.\"\n",
        "\n",
        "    # Embed the user query\n",
        "    query_embedding = biobert.encode([query], convert_to_tensor=True)[0].cpu().numpy()\n",
        "\n",
        "    # Compute cosine similarities\n",
        "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
        "\n",
        "    # Get the top-k most similar docs\n",
        "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
        "\n",
        "    results = []\n",
        "    for idx in top_indices:\n",
        "        results.append({\n",
        "            \"doc\": docs[idx],\n",
        "            \"similarity\": float(similarities[idx])\n",
        "        })\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "quT8mlBWydld"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# API"
      ],
      "metadata": {
        "id": "G3jIU2h_0q6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask flask-cors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EXzwa7BuraE",
        "outputId": "3cb8d49a-f0ae-4c10-b0b7-65ff7826bd97"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.11/dist-packages (6.0.1)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)  # Enable CORS for all routes\n",
        "\n",
        "@app.route('/embed-doc', methods=['POST'])\n",
        "def embed_doc():\n",
        "    data = request.get_json()\n",
        "    text = data.get(\"text\", \"\")\n",
        "    if not text:\n",
        "        return jsonify({\"error\": \"Missing 'text' field.\"}), 400\n",
        "\n",
        "    add_doc(text)\n",
        "    return jsonify({\"message\": \"âœ… Document embedded.\", \"total_docs\": len(docs)})\n",
        "\n",
        "@app.route('/query', methods=['POST'])\n",
        "def query():\n",
        "    data = request.get_json()\n",
        "    query = data.get(\"query\", \"\")\n",
        "    if not query:\n",
        "        return jsonify({\"error\": \"Missing 'query' field.\"}), 400\n",
        "\n",
        "    results = find_most_similar_doc(query, top_k=1)\n",
        "    return jsonify(results)"
      ],
      "metadata": {
        "id": "YCJnHIxIwKlL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scHbG0Zz08UL",
        "outputId": "633d521f-5082-41e2-887e-15a8c9c212ee"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.11)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token = input('Enter ngrok auth token: ')"
      ],
      "metadata": {
        "id": "zumlr_GW16kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Replace with your token from ngrok.com\n",
        "ngrok.set_auth_token(token)"
      ],
      "metadata": {
        "id": "-0JinrBL0_B4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return \"Flask is running!\"\n",
        "\n",
        "@app.route('/ask', methods=['POST'])\n",
        "def ask():\n",
        "    print(\"ðŸ“¥ Received /ask request\")\n",
        "    data = request.json\n",
        "    question = data.get(\"question\", \"\")\n",
        "    return jsonify({\"answer\": f\"You asked: {question}\"})\n",
        "\n",
        "# Start Flask app in a thread\n",
        "def run_app():\n",
        "    app.run(port=5000)\n",
        "\n",
        "# Start the Flask app\n",
        "thread = threading.Thread(target=run_app)\n",
        "thread.start()\n",
        "\n",
        "# Setup ngrok\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"ðŸŒ Public URL:\", public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ19knyE1C8B",
        "outputId": "5176035f-599b-4563-b0ed-7aa4629a27b5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŒ Public URL: NgrokTunnel: \"https://3afd-34-87-65-143.ngrok-free.app\" -> \"http://localhost:5000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import signal\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Kill ngrok\n",
        "ngrok.kill()\n",
        "\n",
        "# Kill the Flask thread by killing the whole Colab process (if needed)\n",
        "os.kill(os.getpid(), signal.SIGKILL)\n",
        "\n",
        "print('Killed')"
      ],
      "metadata": {
        "id": "0kPiGzdl5GTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U0_LHRrAIbcz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}