{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# WellnessGrid LLM Integration Notebook\n",
        "\n",
        "This notebook demonstrates the LLM functionality used in the WellnessGrid app using:\n",
        "- **BioGPT-Large** for text generation\n",
        "- **BioBERT** for embeddings\n",
        "- **Hugging Face Inference API**\n",
        "\n",
        "## Setup Instructions\n",
        "1. Run this notebook in Google Colab\n",
        "2. Set your Hugging Face API token in the first cell\n",
        "3. Execute cells in order to test the functionality\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install requests numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any, Optional\n",
        "import time\n",
        "\n",
        "# Configuration\n",
        "HUGGING_FACE_API_TOKEN = \"\"  # Add your Hugging Face API token here\n",
        "USE_MOCK_MODE = True  # Set to False to use real API calls\n",
        "\n",
        "# API endpoints\n",
        "BIOGPT_URL = \"https://api-inference.huggingface.co/models/microsoft/BioGPT-Large\"\n",
        "BIOBERT_URL = \"https://api-inference.huggingface.co/models/dmis-lab/biobert-base-cased-v1.1\"\n",
        "\n",
        "# Headers for API requests\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {HUGGING_FACE_API_TOKEN}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "print(f\"Configuration loaded. Mock mode: {USE_MOCK_MODE}\")\n",
        "if HUGGING_FACE_API_TOKEN:\n",
        "    print(\"✅ Hugging Face API token provided\")\n",
        "else:\n",
        "    print(\"⚠️ No Hugging Face API token provided - will use mock mode\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mock health documents database\n",
        "HEALTH_DOCUMENTS = [\n",
        "    {\n",
        "        \"id\": \"1\",\n",
        "        \"title\": \"Managing Diabetes Through Diet\",\n",
        "        \"content\": \"A balanced diet is crucial for managing diabetes. Focus on complex carbohydrates, lean proteins, and healthy fats. Monitor blood sugar levels regularly and work with a healthcare provider to adjust your meal plan as needed.\",\n",
        "        \"type\": \"article\",\n",
        "        \"tags\": [\"diabetes\", \"diet\", \"nutrition\"]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"2\",\n",
        "        \"title\": \"Exercise Guidelines for Heart Health\",\n",
        "        \"content\": \"Regular cardiovascular exercise strengthens the heart muscle and improves circulation. Aim for at least 150 minutes of moderate-intensity exercise per week. Include both aerobic activities and strength training for optimal heart health.\",\n",
        "        \"type\": \"guideline\",\n",
        "        \"tags\": [\"heart disease\", \"exercise\", \"cardiovascular\"]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"3\",\n",
        "        \"title\": \"Understanding High Blood Pressure\",\n",
        "        \"content\": \"Hypertension affects millions worldwide. Key management strategies include reducing sodium intake, maintaining a healthy weight, regular exercise, stress management, and medication adherence when prescribed.\",\n",
        "        \"type\": \"educational\",\n",
        "        \"tags\": [\"hypertension\", \"blood pressure\", \"lifestyle\"]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"4\",\n",
        "        \"title\": \"Sleep and Mental Health Connection\",\n",
        "        \"content\": \"Quality sleep is essential for mental health. Poor sleep can worsen anxiety and depression. Establish a consistent sleep schedule, create a relaxing bedtime routine, and limit screen time before bed.\",\n",
        "        \"type\": \"research\",\n",
        "        \"tags\": [\"anxiety\", \"depression\", \"sleep\", \"mental health\"]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"5\",\n",
        "        \"title\": \"Arthritis Pain Management\",\n",
        "        \"content\": \"Arthritis pain can be managed through a combination of medication, physical therapy, gentle exercise, heat/cold therapy, and lifestyle modifications. Work with your healthcare team to develop a comprehensive pain management plan.\",\n",
        "        \"type\": \"treatment\",\n",
        "        \"tags\": [\"arthritis\", \"pain management\", \"mobility\"]\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"Loaded {len(HEALTH_DOCUMENTS)} health documents for context\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_embedding_real(text: str) -> List[float]:\n",
        "    \"\"\"Generate embeddings using BioBERT via Hugging Face API\"\"\"\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            BIOBERT_URL,\n",
        "            headers=headers,\n",
        "            json={\"inputs\": text, \"options\": {\"wait_for_model\": True}}\n",
        "        )\n",
        "        \n",
        "        if response.status_code == 200:\n",
        "            # BioBERT returns pooled embeddings\n",
        "            result = response.json()\n",
        "            if isinstance(result, list) and len(result) > 0:\n",
        "                return result[0]  # Return the first (and usually only) embedding\n",
        "            return result\n",
        "        else:\n",
        "            print(f\"Embedding API error: {response.status_code} - {response.text}\")\n",
        "            return generate_embedding_mock(text)\n",
        "    except Exception as e:\n",
        "        print(f\"Embedding error: {e}\")\n",
        "        return generate_embedding_mock(text)\n",
        "\n",
        "def generate_embedding_mock(text: str) -> List[float]:\n",
        "    \"\"\"Generate mock embeddings for testing\"\"\"\n",
        "    # Simple hash-based mock embedding\n",
        "    import hashlib\n",
        "    hash_object = hashlib.md5(text.encode())\n",
        "    hash_hex = hash_object.hexdigest()\n",
        "    \n",
        "    # Convert to pseudo-random 768-dimensional vector (BioBERT size)\n",
        "    np.random.seed(int(hash_hex[:8], 16))\n",
        "    embedding = np.random.normal(0, 1, 768).tolist()\n",
        "    return embedding\n",
        "\n",
        "def generate_embedding(text: str) -> List[float]:\n",
        "    \"\"\"Generate embeddings with fallback to mock\"\"\"\n",
        "    if USE_MOCK_MODE or not HUGGING_FACE_API_TOKEN:\n",
        "        return generate_embedding_mock(text)\n",
        "    return generate_embedding_real(text)\n",
        "\n",
        "print(\"Embedding functions loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cosine_similarity(a: List[float], b: List[float]) -> float:\n",
        "    \"\"\"Calculate cosine similarity between two vectors\"\"\"\n",
        "    a_np = np.array(a)\n",
        "    b_np = np.array(b)\n",
        "    \n",
        "    dot_product = np.dot(a_np, b_np)\n",
        "    norm_a = np.linalg.norm(a_np)\n",
        "    norm_b = np.linalg.norm(b_np)\n",
        "    \n",
        "    if norm_a == 0 or norm_b == 0:\n",
        "        return 0\n",
        "    \n",
        "    return dot_product / (norm_a * norm_b)\n",
        "\n",
        "def find_relevant_documents(query: str, health_conditions: List[str] = None, limit: int = 3) -> List[Dict]:\n",
        "    \"\"\"Find documents relevant to the query and health conditions\"\"\"\n",
        "    query_embedding = generate_embedding(query)\n",
        "    \n",
        "    # Add health conditions to query context\n",
        "    if health_conditions:\n",
        "        enhanced_query = f\"{query} {' '.join(health_conditions)}\"\n",
        "        query_embedding = generate_embedding(enhanced_query)\n",
        "    \n",
        "    # Calculate similarity with all documents\n",
        "    similarities = []\n",
        "    for doc in HEALTH_DOCUMENTS:\n",
        "        doc_embedding = generate_embedding(doc['content'])\n",
        "        similarity = cosine_similarity(query_embedding, doc_embedding)\n",
        "        \n",
        "        # Boost similarity if health conditions match document tags\n",
        "        if health_conditions:\n",
        "            condition_match = any(condition.lower() in [tag.lower() for tag in doc['tags']] for condition in health_conditions)\n",
        "            if condition_match:\n",
        "                similarity += 0.2  # Boost for condition relevance\n",
        "        \n",
        "        similarities.append((doc, similarity))\n",
        "    \n",
        "    # Sort by similarity and return top results\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "    return [doc for doc, _ in similarities[:limit]]\n",
        "\n",
        "print(\"Similarity functions loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_answer_real(prompt: str) -> str:\n",
        "    \"\"\"Generate answer using BioGPT via Hugging Face API\"\"\"\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            BIOGPT_URL,\n",
        "            headers=headers,\n",
        "            json={\n",
        "                \"inputs\": prompt,\n",
        "                \"parameters\": {\n",
        "                    \"max_new_tokens\": 200,\n",
        "                    \"temperature\": 0.7,\n",
        "                    \"do_sample\": True,\n",
        "                    \"return_full_text\": False\n",
        "                },\n",
        "                \"options\": {\"wait_for_model\": True}\n",
        "            }\n",
        "        )\n",
        "        \n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            if isinstance(result, list) and len(result) > 0:\n",
        "                return result[0].get('generated_text', '').strip()\n",
        "            return str(result).strip()\n",
        "        else:\n",
        "            print(f\"Text generation API error: {response.status_code} - {response.text}\")\n",
        "            return generate_answer_mock(prompt)\n",
        "    except Exception as e:\n",
        "        print(f\"Text generation error: {e}\")\n",
        "        return generate_answer_mock(prompt)\n",
        "\n",
        "def generate_answer_mock(prompt: str) -> str:\n",
        "    \"\"\"Generate mock answer for testing\"\"\"\n",
        "    mock_responses = [\n",
        "        \"Based on current medical guidelines, it's important to consult with your healthcare provider for personalized advice. General recommendations include maintaining a balanced diet, regular exercise, and following prescribed treatments.\",\n",
        "        \"This is a complex health topic that requires individualized care. Consider discussing these symptoms or concerns with a medical professional who can provide guidance based on your specific health history and current condition.\",\n",
        "        \"Health management often involves a combination of lifestyle modifications, medical treatments, and regular monitoring. Your healthcare team can help develop a comprehensive plan tailored to your needs.\",\n",
        "        \"While general health information can be helpful, it's crucial to work with qualified healthcare providers for diagnosis and treatment decisions. They can consider your complete medical history and current health status.\"\n",
        "    ]\n",
        "    \n",
        "    # Use a simple hash to consistently return the same mock response for the same prompt\n",
        "    import hashlib\n",
        "    hash_object = hashlib.md5(prompt.encode())\n",
        "    hash_int = int(hash_object.hexdigest()[:8], 16)\n",
        "    return mock_responses[hash_int % len(mock_responses)]\n",
        "\n",
        "def generate_answer(prompt: str) -> str:\n",
        "    \"\"\"Generate answer with fallback to mock\"\"\"\n",
        "    if USE_MOCK_MODE or not HUGGING_FACE_API_TOKEN:\n",
        "        return generate_answer_mock(prompt)\n",
        "    return generate_answer_real(prompt)\n",
        "\n",
        "print(\"Text generation functions loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ask_wellness_llm(question: str, health_conditions: List[str] = None) -> Dict[str, Any]:\n",
        "    \"\"\"Main function to ask the Wellness LLM a question\"\"\"\n",
        "    try:\n",
        "        # Find relevant documents\n",
        "        relevant_docs = find_relevant_documents(question, health_conditions)\n",
        "        \n",
        "        # Build context from relevant documents\n",
        "        context = \"\\n\\n\".join([\n",
        "            f\"Source: {doc['title']}\\nContent: {doc['content']}\"\n",
        "            for doc in relevant_docs\n",
        "        ])\n",
        "        \n",
        "        # Build prompt with context and health conditions\n",
        "        prompt_parts = []\n",
        "        \n",
        "        if health_conditions:\n",
        "            prompt_parts.append(f\"Patient health conditions: {', '.join(health_conditions)}\")\n",
        "        \n",
        "        if context:\n",
        "            prompt_parts.append(f\"Relevant medical information:\\n{context}\")\n",
        "        \n",
        "        prompt_parts.append(f\"Question: {question}\")\n",
        "        prompt_parts.append(\"Please provide a helpful, evidence-based response:\")\n",
        "        \n",
        "        full_prompt = \"\\n\\n\".join(prompt_parts)\n",
        "        \n",
        "        # Generate answer\n",
        "        answer = generate_answer(full_prompt)\n",
        "        \n",
        "        # Format sources\n",
        "        sources = [{\n",
        "            \"title\": doc['title'],\n",
        "            \"type\": doc['type'],\n",
        "            \"id\": doc['id']\n",
        "        } for doc in relevant_docs]\n",
        "        \n",
        "        return {\n",
        "            \"answer\": answer,\n",
        "            \"sources\": sources,\n",
        "            \"health_conditions\": health_conditions or [],\n",
        "            \"mode\": \"mock\" if (USE_MOCK_MODE or not HUGGING_FACE_API_TOKEN) else \"real\"\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"error\": f\"An error occurred while processing your question: {str(e)}\",\n",
        "            \"answer\": \"I apologize, but I'm unable to process your question right now. Please try again later or consult with a healthcare professional.\",\n",
        "            \"sources\": [],\n",
        "            \"health_conditions\": health_conditions or [],\n",
        "            \"mode\": \"error\"\n",
        "        }\n",
        "\n",
        "print(\"Main LLM function loaded\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Example Usage\n",
        "\n",
        "Now let's test the LLM functionality with some example questions:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 1: Basic health question\n",
        "question1 = \"What are some good exercises for heart health?\"\n",
        "result1 = ask_wellness_llm(question1)\n",
        "\n",
        "print(\"=== Example 1: Basic Health Question ===\")\n",
        "print(f\"Question: {question1}\")\n",
        "print(f\"\\nAnswer: {result1['answer']}\")\n",
        "print(f\"\\nMode: {result1['mode']}\")\n",
        "print(f\"\\nSources ({len(result1['sources'])}):\")\n",
        "for i, source in enumerate(result1['sources'], 1):\n",
        "    print(f\"  {i}. {source['title']} ({source['type']})\")\n",
        "print(\"\\n\" + \"=\"*50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 2: Question with health conditions\n",
        "question2 = \"How should I manage my diet?\"\n",
        "conditions2 = [\"diabetes\", \"hypertension\"]\n",
        "result2 = ask_wellness_llm(question2, conditions2)\n",
        "\n",
        "print(\"=== Example 2: Question with Health Conditions ===\")\n",
        "print(f\"Question: {question2}\")\n",
        "print(f\"Health Conditions: {', '.join(conditions2)}\")\n",
        "print(f\"\\nAnswer: {result2['answer']}\")\n",
        "print(f\"\\nMode: {result2['mode']}\")\n",
        "print(f\"\\nSources ({len(result2['sources'])}):\")\n",
        "for i, source in enumerate(result2['sources'], 1):\n",
        "    print(f\"  {i}. {source['title']} ({source['type']})\")\n",
        "print(\"\\n\" + \"=\"*50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 3: Mental health question\n",
        "question3 = \"I'm having trouble sleeping and feeling anxious. What can help?\"\n",
        "conditions3 = [\"anxiety\"]\n",
        "result3 = ask_wellness_llm(question3, conditions3)\n",
        "\n",
        "print(\"=== Example 3: Mental Health Question ===\")\n",
        "print(f\"Question: {question3}\")\n",
        "print(f\"Health Conditions: {', '.join(conditions3)}\")\n",
        "print(f\"\\nAnswer: {result3['answer']}\")\n",
        "print(f\"\\nMode: {result3['mode']}\")\n",
        "print(f\"\\nSources ({len(result3['sources'])}):\")\n",
        "for i, source in enumerate(result3['sources'], 1):\n",
        "    print(f\"  {i}. {source['title']} ({source['type']})\")\n",
        "print(\"\\n\" + \"=\"*50)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Testing with Real API\n",
        "\n",
        "To test with the real Hugging Face API:\n",
        "1. Set your `HUGGING_FACE_API_TOKEN` in the configuration cell\n",
        "2. Set `USE_MOCK_MODE = False`\n",
        "3. Re-run the configuration cell and then the examples\n",
        "\n",
        "**Note:** Real API calls may take longer and require a valid Hugging Face account with API access.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment and run this cell to test with real API\n",
        "# Make sure to set your HUGGING_FACE_API_TOKEN first!\n",
        "\n",
        "# USE_MOCK_MODE = False\n",
        "# print(f\"Switched to real API mode. Token available: {bool(HUGGING_FACE_API_TOKEN)}\")\n",
        "\n",
        "# # Test with a simple question\n",
        "# test_question = \"What is diabetes?\"\n",
        "# test_result = ask_wellness_llm(test_question)\n",
        "# print(f\"\\nTest Question: {test_question}\")\n",
        "# print(f\"Answer: {test_result['answer']}\")\n",
        "# print(f\"Mode: {test_result['mode']}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Customization\n",
        "\n",
        "You can customize this notebook by:\n",
        "\n",
        "1. **Adding more health documents** to the `HEALTH_DOCUMENTS` list\n",
        "2. **Modifying the prompt structure** in the `ask_wellness_llm` function\n",
        "3. **Adjusting the similarity threshold** for document retrieval\n",
        "4. **Experimenting with different BioGPT parameters** (temperature, max_tokens, etc.)\n",
        "5. **Using different models** by changing the API URLs\n",
        "\n",
        "## Integration with WellnessGrid App\n",
        "\n",
        "This notebook replicates the functionality found in:\n",
        "- `app/api/ask/route.ts` - Main API endpoint\n",
        "- `app/chat/page.tsx` - Chat interface integration\n",
        "\n",
        "The same functions and logic can be used in both environments for consistent results.\n",
        "\n",
        "## Interactive Testing\n",
        "\n",
        "Use the cell below to test your own questions:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive testing - modify these variables and run the cell\n",
        "your_question = \"Tell me about managing high blood pressure\"\n",
        "your_conditions = [\"hypertension\", \"diabetes\"]  # Add your conditions here\n",
        "\n",
        "# Run your custom query\n",
        "custom_result = ask_wellness_llm(your_question, your_conditions)\n",
        "\n",
        "print(\"=== Your Custom Question ===\")\n",
        "print(f\"Question: {your_question}\")\n",
        "if your_conditions:\n",
        "    print(f\"Health Conditions: {', '.join(your_conditions)}\")\n",
        "print(f\"\\nAnswer: {custom_result['answer']}\")\n",
        "print(f\"\\nMode: {custom_result['mode']}\")\n",
        "print(f\"\\nSources ({len(custom_result['sources'])}):\")\n",
        "for i, source in enumerate(custom_result['sources'], 1):\n",
        "    print(f\"  {i}. {source['title']} ({source['type']})\")\n",
        "\n",
        "# Show the full prompt that was sent to the model (for debugging)\n",
        "print(f\"\\n=== Debug Info ===\")\n",
        "print(f\"Total health documents: {len(HEALTH_DOCUMENTS)}\")\n",
        "print(f\"API Mode: {'Real' if not USE_MOCK_MODE and HUGGING_FACE_API_TOKEN else 'Mock'}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
