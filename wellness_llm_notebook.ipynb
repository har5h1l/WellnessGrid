{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "8F3xVTTbsoCX"
      },
      "source": [
        "# WellnessGrid LLM Integration Notebook\n",
        "\n",
        "This notebook demonstrates the LLM functionality used in the WellnessGrid app using:\n",
        "- **BioGPT-Large** for text generation\n",
        "- **BioBERT** for embeddings\n",
        "- **Hugging Face Inference API**\n",
        "\n",
        "## Setup Instructions\n",
        "1. Run this notebook in Google Colab\n",
        "2. Set your Hugging Face API token in the first cell\n",
        "3. Execute cells in order to test the functionality\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97xQThaysoCa"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install transformers flask flask-cors pyngrok --quiet\n",
        "!pip install sentence-transformers scikit-learn --quiet\n",
        "!pip install sacremoses --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Models"
      ],
      "metadata": {
        "id": "6-q-NKKhtYgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BioGPT-Large\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"microsoft/BioGPT-Large\")"
      ],
      "metadata": {
        "id": "kGQkAFxLszSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "8Gks2AfwyS0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "biobert = SentenceTransformer('pritamdeka/S-BioBert-snli-multinli-stsb', device=device)"
      ],
      "metadata": {
        "id": "8--dIof6x2Yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Document Embeddings & Retriver"
      ],
      "metadata": {
        "id": "JtG1OmfszljK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = []\n",
        "doc_embedings = []"
      ],
      "metadata": {
        "id": "uFaTjEbTwKvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_doc(text):\n",
        "    # Embed the incoming doc using BioBERT\n",
        "    embedding = biobert.encode([text], convert_to_tensor=True)[0].cpu().numpy()\n",
        "\n",
        "    # Store in memory\n",
        "    docs.append(text)\n",
        "    doc_embeddings.append(embedding)\n",
        "\n",
        "    print(f\"‚úÖ Added document. Total docs: {len(docs)}\")"
      ],
      "metadata": {
        "id": "smA7-I0X0UbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_most_similar_doc(query, top_k=1):\n",
        "    if not doc_embeddings:\n",
        "        return \"‚ùå No documents in memory.\"\n",
        "\n",
        "    # Embed the user query\n",
        "    query_embedding = biobert.encode([query], convert_to_tensor=True)[0].cpu().numpy()\n",
        "\n",
        "    # Compute cosine similarities\n",
        "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
        "\n",
        "    # Get the top-k most similar docs\n",
        "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
        "\n",
        "    results = []\n",
        "    for idx in top_indices:\n",
        "        results.append({\n",
        "            \"doc\": docs[idx],\n",
        "            \"similarity\": float(similarities[idx])\n",
        "        })\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "quT8mlBWydld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# API"
      ],
      "metadata": {
        "id": "G3jIU2h_0q6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask flask-cors"
      ],
      "metadata": {
        "id": "1EXzwa7BuraE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)  # Enable CORS for all routes\n",
        "\n",
        "@app.route('/embed-doc', methods=['POST'])\n",
        "def embed_doc():\n",
        "    data = request.get_json()\n",
        "    text = data.get(\"text\", \"\")\n",
        "    if not text:\n",
        "        return jsonify({\"error\": \"Missing 'text' field.\"}), 400\n",
        "\n",
        "    add_doc(text)\n",
        "    return jsonify({\"message\": \"‚úÖ Document embedded.\", \"total_docs\": len(docs)})\n",
        "\n",
        "@app.route('/query', methods=['POST'])\n",
        "def query():\n",
        "    data = request.get_json()\n",
        "    query = data.get(\"query\", \"\")\n",
        "    if not query:\n",
        "        return jsonify({\"error\": \"Missing 'query' field.\"}), 400\n",
        "\n",
        "    results = find_most_similar_doc(query, top_k=1)\n",
        "    return jsonify(results)"
      ],
      "metadata": {
        "id": "YCJnHIxIwKlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "scHbG0Zz08UL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = input('Enter ngrok auth token: ')"
      ],
      "metadata": {
        "id": "zumlr_GW16kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Replace with your token from ngrok.com\n",
        "ngrok.set_auth_token(token)"
      ],
      "metadata": {
        "id": "-0JinrBL0_B4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Flask app in background\n",
        "import threading\n",
        "\n",
        "def run_flask():\n",
        "    from flask_cors import CORS\n",
        "    CORS(app)\n",
        "    app.run(port=5000)\n",
        "\n",
        "thread = threading.Thread(target=run_flask)\n",
        "thread.start()\n",
        "\n",
        "# Start ngrok tunnel\n",
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"üöÄ Public URL:\", public_url)"
      ],
      "metadata": {
        "id": "bQ19knyE1C8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0kPiGzdl5GTH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}