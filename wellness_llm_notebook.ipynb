{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "id": "8F3xVTTbsoCX",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# WellnessGrid LLM Integration Notebook\n",
        "\n",
        "This notebook demonstrates the LLM functionality used in the WellnessGrid app using:\n",
        "- **BioGPT** for medical text generation (faster than Med42)\n",
        "- **BioBERT** for embeddings\n",
        "- **Flask API with ngrok tunneling**\n",
        "\n",
        "## Setup Instructions\n",
        "1. Run this notebook in Google Colab with GPU enabled\n",
        "2. Execute cells in order to test the functionality\n",
        "3. Enter your ngrok auth token when prompted\n",
        "4. Use the generated ngrok URL in your WellnessGrid app\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "97xQThaysoCa"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install transformers flask flask-cors pyngrok --quiet\n",
        "!pip install sentence-transformers scikit-learn --quiet\n",
        "!pip install sacremoses --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-q-NKKhtYgf"
      },
      "source": [
        "# Load Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "480df5c94f59457f9651fe1434e6b788",
            "f0f78485c3e34a08ba9d07f5da228e2f",
            "4530a7e6c48b4e088e507fa00a7e8bf5",
            "c5958b62584941d0af34f1716bb82439",
            "f78c9ebddbde41bebb18da32fccd6761",
            "85fb8f20d6d94c2d9266356370852216",
            "bd1980416ced4f7d8eafefd4a7e0f2b4",
            "70c034d7b96744648bcea181d822e90b",
            "6732b14abe704cfea1a2bfb3111cb8e5",
            "11ea1e1513d243b1925dfc4988071cfb",
            "24a4efa86df943ca869e9d596ad00486"
          ]
        },
        "id": "kGQkAFxLszSy",
        "outputId": "3565b23d-00bf-4d8f-ef5e-c9dfd761ffc1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "480df5c94f59457f9651fe1434e6b788",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "# Load BioGPT - lighter and faster medical model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BioGPT\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/BioGPT\",\n",
        "    torch_dtype=torch.float16,  # Use half precision for faster inference\n",
        "    low_cpu_mem_usage=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Gks2AfwyS0Y",
        "outputId": "ff3eac23-c9a6-4043-a5bb-c42b939db2ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Using device: cuda\n",
            "ü§ñ Med42 model loaded with automatic device mapping\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)  # Move BioGPT to GPU\n",
        "print(f\"üîß Using device: {device}\")\n",
        "print(f\"ü§ñ BioGPT model loaded and moved to {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8--dIof6x2Yt"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "biobert = SentenceTransformer('pritamdeka/S-BioBert-snli-multinli-stsb', device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtG1OmfszljK"
      },
      "source": [
        "# Document Embeddings & Retriver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uFaTjEbTwKvT"
      },
      "outputs": [],
      "source": [
        "docs = []\n",
        "doc_embeddings = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "smA7-I0X0UbL"
      },
      "outputs": [],
      "source": [
        "def add_doc(text):\n",
        "    # Embed the incoming doc using BioBERT\n",
        "    embedding = biobert.encode([text], convert_to_tensor=True)[0].cpu().numpy()\n",
        "\n",
        "    # Store in memory\n",
        "    docs.append(text)\n",
        "    doc_embeddings.append(embedding)\n",
        "\n",
        "    print(f\"‚úÖ Added document. Total docs: {len(docs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "quT8mlBWydld"
      },
      "outputs": [],
      "source": [
        "def find_most_similar_doc(query, top_k=1):\n",
        "    if not doc_embeddings:\n",
        "        return \"‚ùå No documents in memory.\"\n",
        "\n",
        "    # Embed the user query\n",
        "    query_embedding = biobert.encode([query], convert_to_tensor=True)[0].cpu().numpy()\n",
        "\n",
        "    # Compute cosine similarities\n",
        "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
        "\n",
        "    # Get the top-k most similar docs\n",
        "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
        "\n",
        "    results = []\n",
        "    for idx in top_indices:\n",
        "        results.append({\n",
        "            \"doc\": docs[idx],\n",
        "            \"similarity\": float(similarities[idx])\n",
        "        })\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3jIU2h_0q6S"
      },
      "source": [
        "# API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EXzwa7BuraE",
        "outputId": "a7ba41d7-05f4-40c9-aaa0-026077a9b329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.11/dist-packages (6.0.1)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install flask flask-cors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YCJnHIxIwKlL"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "import torch\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)  # Enable CORS for all routes\n",
        "\n",
        "def generate_biogpt_response(prompt, max_length=100):\n",
        "    \"\"\"Generate medical response using BioGPT\"\"\"\n",
        "    try:\n",
        "        # Set pad token if not already set\n",
        "        if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "        \n",
        "        # Encode the prompt\n",
        "        inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "        \n",
        "        # Generate response\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                inputs,\n",
        "                max_length=len(inputs[0]) + 50,  # Add tokens to input length\n",
        "                num_return_sequences=1,\n",
        "                temperature=0.7,\n",
        "                do_sample=True,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id,\n",
        "                no_repeat_ngram_size=2\n",
        "            )\n",
        "        \n",
        "        # Decode and clean response\n",
        "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        # Remove the original prompt from response\n",
        "        if prompt in response:\n",
        "            response = response.replace(prompt, \"\").strip()\n",
        "        \n",
        "        # Clean up response\n",
        "        response = response.strip()\n",
        "        if not response:\n",
        "            response = \"I understand your question about health. Please consult with a healthcare professional for personalized medical advice.\"\n",
        "        \n",
        "        return response\n",
        "    except Exception as e:\n",
        "        return f\"I apologize, but I encountered an error processing your question. Please try rephrasing your question or consult with a healthcare professional.\"\n",
        "\n",
        "@app.route('/embed-doc', methods=['POST'])\n",
        "def embed_doc():\n",
        "    data = request.get_json()\n",
        "    text = data.get(\"text\", \"\")\n",
        "    if not text:\n",
        "        return jsonify({\"error\": \"Missing 'text' field.\"}), 400\n",
        "\n",
        "    add_doc(text)\n",
        "    return jsonify({\"message\": \"‚úÖ Document embedded.\", \"total_docs\": len(docs)})\n",
        "\n",
        "@app.route('/query', methods=['POST'])\n",
        "def query():\n",
        "    data = request.get_json()\n",
        "    query = data.get(\"query\", \"\")\n",
        "    if not query:\n",
        "        return jsonify({\"error\": \"Missing 'query' field.\"}), 400\n",
        "\n",
        "    results = find_most_similar_doc(query, top_k=1)\n",
        "    return jsonify(results)\n",
        "\n",
        "@app.route('/ask', methods=['POST'])\n",
        "def ask_biogpt():\n",
        "    \"\"\"Main endpoint for WellnessGrid app - matches the expected format\"\"\"\n",
        "    try:\n",
        "        data = request.get_json()\n",
        "        question = data.get(\"question\", \"\")\n",
        "        \n",
        "        if not question:\n",
        "            return jsonify({\"error\": \"Missing 'question' field.\"}), 400\n",
        "        \n",
        "        # Find relevant documents\n",
        "        relevant_docs = find_most_similar_doc(question, top_k=2)\n",
        "        \n",
        "        # Prepare context from documents\n",
        "        context = \"\"\n",
        "        sources = []\n",
        "        if relevant_docs and relevant_docs != \"‚ùå No documents in memory.\":\n",
        "            for doc_data in relevant_docs:\n",
        "                context += f\"Context: {doc_data['doc'][:200]}...\\n\"\n",
        "                sources.append({\n",
        "                    \"title\": \"Health Document\", \n",
        "                    \"content\": doc_data['doc'][:100] + \"...\",\n",
        "                    \"similarity\": doc_data['similarity']\n",
        "                })\n",
        "        \n",
        "        # Create medical prompt for BioGPT\n",
        "        medical_prompt = f\"Medical Question: {question}\\n{context}Answer:\"\n",
        "        \n",
        "        # Generate response using BioGPT\n",
        "        ai_response = generate_biogpt_response(medical_prompt, max_length=150)\n",
        "        \n",
        "        # Return in expected format for WellnessGrid app\n",
        "        return jsonify({\n",
        "            \"response\": ai_response,\n",
        "            \"sources\": sources,\n",
        "            \"mockMode\": False\n",
        "        })\n",
        "        \n",
        "    except Exception as e:\n",
        "        return jsonify({\n",
        "            \"response\": f\"I apologize, but I encountered an error processing your question: {str(e)}\",\n",
        "            \"sources\": [],\n",
        "            \"mockMode\": True\n",
        "        }), 500\n",
        "\n",
        "@app.route('/health', methods=['GET'])\n",
        "def health_check():\n",
        "    \"\"\"Health check endpoint\"\"\"\n",
        "    return jsonify({\n",
        "        \"status\": \"healthy\",\n",
        "        \"model\": \"BioGPT\",\n",
        "        \"documents_loaded\": len(docs)\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scHbG0Zz08UL",
        "outputId": "6d59d525-8f77-4879-e63a-a9cd63416f8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.11)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-0JinrBL0_B4"
      },
      "outputs": [],
      "source": [
        "# Get ngrok auth token from user\n",
        "from getpass import getpass\n",
        "print(\"üîë Please enter your ngrok auth token (get it from https://ngrok.com)\")\n",
        "print(\"   Your token will be hidden for security\")\n",
        "token = getpass(\"Enter ngrok auth token: \")\n",
        "\n",
        "# Setup ngrok\n",
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(token)\n",
        "print(\"‚úÖ Ngrok token set successfully!\")\n",
        "\n",
        "# Add sample health documents for testing\n",
        "print(\"üìö Adding sample health documents...\")\n",
        "\n",
        "sample_docs = [\n",
        "    \"Diabetes is a chronic condition that affects how your body processes blood glucose. Type 2 diabetes can often be managed through diet, exercise, and medication. Regular monitoring of blood sugar levels is essential.\",\n",
        "    \"Hypertension, or high blood pressure, is often called the 'silent killer' because it usually has no symptoms. It can be managed through lifestyle changes including reducing sodium intake, regular exercise, and stress management.\",\n",
        "    \"Depression is a mood disorder that affects how you feel, think, and handle daily activities. Treatment may include psychotherapy, medication, or a combination of both. Regular exercise and social support are also beneficial.\",\n",
        "    \"Anxiety disorders are characterized by excessive worry or fear. Cognitive behavioral therapy (CBT) and relaxation techniques can be effective treatments along with medication when necessary.\",\n",
        "    \"Heart disease prevention includes maintaining a healthy diet low in saturated fats, regular physical activity, not smoking, and managing stress levels.\"\n",
        "]\n",
        "\n",
        "for doc in sample_docs:\n",
        "    add_doc(doc)\n",
        "\n",
        "print(\"‚úÖ Sample documents loaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test BioGPT model with a simple medical question\n",
        "print(\"üß™ Testing BioGPT model...\")\n",
        "\n",
        "test_prompt = \"What is diabetes?\"\n",
        "test_response = generate_biogpt_response(test_prompt, max_length=100)\n",
        "\n",
        "print(f\"Question: {test_prompt}\")\n",
        "print(f\"BioGPT Response: {test_response}\")\n",
        "print(\"‚úÖ BioGPT test completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdH_5gtxiQ3G"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import signal\n",
        "# from pyngrok import ngrok\n",
        "\n",
        "# # Kill ngrok\n",
        "# ngrok.kill()\n",
        "\n",
        "# # Kill the Flask thread by killing the whole Colab process (if needed)\n",
        "# os.kill(os.getpid(), signal.SIGKILL)\n",
        "\n",
        "# print('Killed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate everything is loaded before starting Flask\n",
        "print(\"üîç Validating setup...\")\n",
        "\n",
        "# Check if models are loaded\n",
        "try:\n",
        "    model_check = model is not None and tokenizer is not None\n",
        "    biobert_check = biobert is not None\n",
        "    docs_check = len(docs) > 0\n",
        "    \n",
        "    if not model_check:\n",
        "        raise ValueError(\"‚ùå BioGPT model or tokenizer not loaded!\")\n",
        "    \n",
        "    if not biobert_check:\n",
        "        raise ValueError(\"‚ùå BioBERT model not loaded!\")\n",
        "    \n",
        "    if not docs_check:\n",
        "        raise ValueError(\"‚ùå No documents loaded!\")\n",
        "    \n",
        "    print(f\"‚úÖ BioGPT model: Loaded\")\n",
        "    print(f\"‚úÖ BioBERT model: Loaded\") \n",
        "    print(f\"‚úÖ Documents: {len(docs)} loaded\")\n",
        "    print(f\"‚úÖ Device: {device}\")\n",
        "    \n",
        "    # Start ngrok tunnel\n",
        "    print(\"üåê Starting ngrok tunnel...\")\n",
        "    public_url = ngrok.connect(5000)\n",
        "    print(f\"üåç Public URL: {public_url}\")\n",
        "    print(\"üìã Copy this URL to your WellnessGrid app configuration!\")\n",
        "    \n",
        "    # Start Flask app\n",
        "    print(\"üöÄ Starting Flask app...\")\n",
        "    print(\"üì° Available endpoints:\")\n",
        "    print(\"  - POST /ask - Main endpoint for WellnessGrid\")\n",
        "    print(\"  - GET /health - Health check\")\n",
        "    print(\"  - POST /embed-doc - Add documents\")\n",
        "    print(\"  - POST /query - Query documents\")\n",
        "    print(\"\\n‚ö†Ô∏è  Keep this cell running to maintain the server!\")\n",
        "    \n",
        "    app.run(host='0.0.0.0', port=5000, debug=False)\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Setup validation failed: {str(e)}\")\n",
        "    print(\"Please run all previous cells in order before starting the Flask app.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oGHLdomw8l8H"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "11ea1e1513d243b1925dfc4988071cfb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24a4efa86df943ca869e9d596ad00486": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4530a7e6c48b4e088e507fa00a7e8bf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70c034d7b96744648bcea181d822e90b",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6732b14abe704cfea1a2bfb3111cb8e5",
            "value": 4
          }
        },
        "480df5c94f59457f9651fe1434e6b788": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0f78485c3e34a08ba9d07f5da228e2f",
              "IPY_MODEL_4530a7e6c48b4e088e507fa00a7e8bf5",
              "IPY_MODEL_c5958b62584941d0af34f1716bb82439"
            ],
            "layout": "IPY_MODEL_f78c9ebddbde41bebb18da32fccd6761"
          }
        },
        "6732b14abe704cfea1a2bfb3111cb8e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70c034d7b96744648bcea181d822e90b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85fb8f20d6d94c2d9266356370852216": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd1980416ced4f7d8eafefd4a7e0f2b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5958b62584941d0af34f1716bb82439": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11ea1e1513d243b1925dfc4988071cfb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_24a4efa86df943ca869e9d596ad00486",
            "value": "‚Äá4/4‚Äá[00:52&lt;00:00,‚Äá16.32s/it]"
          }
        },
        "f0f78485c3e34a08ba9d07f5da228e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85fb8f20d6d94c2d9266356370852216",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bd1980416ced4f7d8eafefd4a7e0f2b4",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "f78c9ebddbde41bebb18da32fccd6761": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
