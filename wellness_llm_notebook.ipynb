{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "id": "XhktVA1mfUHv",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "NgkWb_jzfUHv"
      },
      "source": []
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "8F3xVTTbsoCX",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# WellnessGrid LLM Integration Notebook\n",
        "\n",
        "This notebook demonstrates the LLM functionality used in the WellnessGrid app using:\n",
        "- **Med42 (Llama3-Med42-8B)** for medical text generation\n",
        "- **BioBERT** for embeddings\n",
        "- **Flask API with ngrok tunneling**\n",
        "\n",
        "## Setup Instructions\n",
        "1. Run this notebook in Google Colab with GPU enabled\n",
        "2. Execute cells in order to test the functionality\n",
        "3. Enter your ngrok auth token when prompted\n",
        "4. Use the generated ngrok URL in your WellnessGrid app\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "97xQThaysoCa"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install transformers flask flask-cors pyngrok --quiet\n",
        "!pip install sentence-transformers scikit-learn --quiet\n",
        "!pip install sacremoses --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-q-NKKhtYgf"
      },
      "source": [
        "# Load Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "kGQkAFxLszSy",
        "outputId": "54cf935c-7a94-4d5d-d175-5b5caf890128",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "e17ad857c6884aec994184b135a7c50d",
            "7bed7c65e3684fe984468680ae73c8c1",
            "630fae45715d4876a8e331908f6f74da",
            "8109bc2b44d74c05bab4f263cdc027e6",
            "b2530948c6e849ee9c372dee5794e282",
            "7a8e598407214db2a90c07f8ec7be0f8",
            "25307efe3d964e76a2abd42b339d0970",
            "74c4c1240380442f903acc60c98b8ca0",
            "cab90b6c58d74172b80c8313806d8d3f",
            "eb71bccac6474194bb4718bef0291ab1",
            "720ce7addcf04943ae30775d46f669e7"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e17ad857c6884aec994184b135a7c50d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu and disk.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Load Med42 - Llama3 based medical model (better than BioGPT)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"m42-health/Llama3-Med42-8B\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"m42-health/Llama3-Med42-8B\",\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "8Gks2AfwyS0Y",
        "outputId": "3df0e9d4-30bf-4d82-c91d-92fb28665c0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Using device: cuda\n",
            "ü§ñ Med42 model loaded with automatic device mapping\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Med42 model already uses device_map=\"auto\", so no need to move manually\n",
        "print(f\"üîß Using device: {device}\")\n",
        "print(f\"ü§ñ Med42 model loaded with automatic device mapping\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "8--dIof6x2Yt"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "biobert = SentenceTransformer('pritamdeka/S-BioBert-snli-multinli-stsb', device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtG1OmfszljK"
      },
      "source": [
        "# Document Embeddings & Retriver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "uFaTjEbTwKvT"
      },
      "outputs": [],
      "source": [
        "docs = []\n",
        "doc_embeddings = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "smA7-I0X0UbL"
      },
      "outputs": [],
      "source": [
        "def add_doc(text):\n",
        "    # Embed the incoming doc using BioBERT\n",
        "    embedding = biobert.encode([text], convert_to_tensor=True)[0].cpu().numpy()\n",
        "\n",
        "    # Store in memory\n",
        "    docs.append(text)\n",
        "    doc_embeddings.append(embedding)\n",
        "\n",
        "    print(f\"‚úÖ Added document. Total docs: {len(docs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "quT8mlBWydld"
      },
      "outputs": [],
      "source": [
        "def find_most_similar_doc(query, top_k=1):\n",
        "    if not doc_embeddings:\n",
        "        return \"‚ùå No documents in memory.\"\n",
        "\n",
        "    # Embed the user query\n",
        "    query_embedding = biobert.encode([query], convert_to_tensor=True)[0].cpu().numpy()\n",
        "\n",
        "    # Compute cosine similarities\n",
        "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
        "\n",
        "    # Get the top-k most similar docs\n",
        "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
        "\n",
        "    results = []\n",
        "    for idx in top_indices:\n",
        "        results.append({\n",
        "            \"doc\": docs[idx],\n",
        "            \"similarity\": float(similarities[idx])\n",
        "        })\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3jIU2h_0q6S"
      },
      "source": [
        "# API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "1EXzwa7BuraE",
        "outputId": "7e454709-a844-476c-c3b5-8f97b52b357a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.11/dist-packages (6.0.1)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install flask flask-cors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "YCJnHIxIwKlL"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)  # Enable CORS for all routes\n",
        "\n",
        "@app.route('/embed-doc', methods=['POST'])\n",
        "def embed_doc():\n",
        "    data = request.get_json()\n",
        "    text = data.get(\"text\", \"\")\n",
        "    if not text:\n",
        "        return jsonify({\"error\": \"Missing 'text' field.\"}), 400\n",
        "\n",
        "    add_doc(text)\n",
        "    return jsonify({\"message\": \"‚úÖ Document embedded.\", \"total_docs\": len(docs)})\n",
        "\n",
        "@app.route('/query', methods=['POST'])\n",
        "def query():\n",
        "    data = request.get_json()\n",
        "    query = data.get(\"query\", \"\")\n",
        "    if not query:\n",
        "        return jsonify({\"error\": \"Missing 'query' field.\"}), 400\n",
        "\n",
        "    results = find_most_similar_doc(query, top_k=1)\n",
        "    return jsonify(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "scHbG0Zz08UL",
        "outputId": "06566afd-8713-4185-86db-681779984296",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.11)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "zumlr_GW16kv",
        "outputId": "6d6af2e9-692d-4f83-8509-d4a858648f28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter ngrok auth token: 2ybG66AaZX2N9M6KmcGfPdj2NL6_6fCydz66gJbAkaCgGyEwf\n"
          ]
        }
      ],
      "source": [
        "token = input('Enter ngrok auth token: ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "-0JinrBL0_B4"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Replace with your token from ngrok.com\n",
        "ngrok.set_auth_token(token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "bQ19knyE1C8B",
        "outputId": "f6b77743-9f81-4426-e174-de7d291912df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All required variables found! Starting Flask app...\n",
            "‚úÖ Added document. Total docs: 8\n",
            "‚úÖ Added document. Total docs: 9\n",
            "‚úÖ Added document. Total docs: 10\n",
            "‚úÖ Added document. Total docs: 11\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Address already in use\n",
            "Port 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåê Public URL: NgrokTunnel: \"https://b0d2-34-125-138-248.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            "ü§ñ Med42 (Llama3-Med42-8B) and BioBERT models loaded and ready!\n",
            "üìö Sample documents embedded: 11\n"
          ]
        }
      ],
      "source": [
        "# ‚ö†Ô∏è CRITICAL: Make sure you ran cells 2-8 BEFORE running this cell!\n",
        "\n",
        "# Check if required variables exist\n",
        "required_vars = ['tokenizer', 'model', 'biobert', 'docs', 'doc_embeddings', 'add_doc', 'find_most_similar_doc']\n",
        "missing_vars = []\n",
        "for var in required_vars:\n",
        "    if var not in globals():\n",
        "        missing_vars.append(var)\n",
        "\n",
        "if missing_vars:\n",
        "    print(\"‚ùå ERROR: Missing required variables:\", missing_vars)\n",
        "    print(\"üîÑ SOLUTION: Please run cells 2-8 in order first!\")\n",
        "    raise Exception(f\"Missing variables: {missing_vars}. Run cells 2-8 first!\")\n",
        "\n",
        "print(\"‚úÖ All required variables found! Starting Flask app...\")\n",
        "\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import torch\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "# Add some sample health documents for testing\n",
        "sample_docs = [\n",
        "    \"Blood pressure is typically measured in millimeters of mercury (mmHg). Normal blood pressure for adults is usually around 120/80 mmHg. High blood pressure (hypertension) is defined as 140/90 mmHg or higher.\",\n",
        "    \"Diabetes is a chronic condition that affects how your body processes blood sugar (glucose). Type 1 diabetes occurs when the pancreas produces little or no insulin. Type 2 diabetes occurs when your body becomes resistant to insulin.\",\n",
        "    \"Regular exercise is essential for maintaining good health. Adults should aim for at least 150 minutes of moderate-intensity aerobic activity per week, plus muscle-strengthening activities twice a week.\",\n",
        "    \"Sleep is crucial for physical and mental health. Adults typically need 7-9 hours of sleep per night. Poor sleep can affect immune function, mood, and cognitive performance.\"\n",
        "]\n",
        "\n",
        "# Add sample documents to our embedding system\n",
        "for doc in sample_docs:\n",
        "    add_doc(doc)\n",
        "\n",
        "def generate_med42_response(query, context=\"\", max_tokens=200):\n",
        "    \"\"\"Generate response using Med42 (Llama3-based medical model)\"\"\"\n",
        "    try:\n",
        "        # Create medical prompt optimized for Llama3 format\n",
        "        if context:\n",
        "            prompt = f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful medical AI assistant. Use the provided context to answer medical questions accurately and safely.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nContext: {context}\\n\\nQuestion: {query}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
        "        else:\n",
        "            prompt = f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful medical AI assistant. Provide accurate and safe medical information.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n{query}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
        "\n",
        "        # Tokenize and generate\n",
        "        inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                inputs,\n",
        "                max_new_tokens=max_tokens,\n",
        "                num_return_sequences=1,\n",
        "                temperature=0.7,\n",
        "                do_sample=True,\n",
        "                pad_token_id=tokenizer.eos_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        # Decode response\n",
        "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # Extract only the assistant response\n",
        "        if \"<|start_header_id|>assistant<|end_header_id|>\" in generated_text:\n",
        "            answer = generated_text.split(\"<|start_header_id|>assistant<|end_header_id|>\")[-1].strip()\n",
        "        else:\n",
        "            answer = generated_text[len(prompt):].strip()\n",
        "\n",
        "        # Clean up any remaining special tokens\n",
        "        answer = answer.replace(\"<|eot_id|>\", \"\").strip()\n",
        "\n",
        "        return answer\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating response: {e}\")\n",
        "        return f\"I apologize, but I encountered an error while processing your question about {query}. Please try rephrasing your question.\"\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return \"WellnessGrid AI Flask API is running!\"\n",
        "\n",
        "@app.route('/ask', methods=['POST'])\n",
        "def ask():\n",
        "    print(\"üì• Received /ask request\")\n",
        "    try:\n",
        "        data = request.json\n",
        "        query = data.get(\"query\", \"\") or data.get(\"question\", \"\")\n",
        "        user_context = data.get(\"userContext\", {})\n",
        "\n",
        "        print(f\"Processing query: {query}\")\n",
        "        print(f\"User context: {user_context}\")\n",
        "\n",
        "        if not query:\n",
        "            return jsonify({\n",
        "                \"response\": \"Please provide a question.\",\n",
        "                \"sources\": [],\n",
        "                \"mockMode\": False\n",
        "            }), 400\n",
        "\n",
        "        # Find relevant documents using BioBERT\n",
        "        similar_docs = find_most_similar_doc(query, top_k=3)\n",
        "\n",
        "        # Prepare context from similar documents\n",
        "        context = \"\"\n",
        "        sources = []\n",
        "\n",
        "        if isinstance(similar_docs, list) and similar_docs:\n",
        "            for i, doc_info in enumerate(similar_docs):\n",
        "                if isinstance(doc_info, dict):\n",
        "                    context += f\"Document {i+1}: {doc_info['doc']}\\n\\n\"\n",
        "                    sources.append({\n",
        "                        \"title\": f\"Health Document {i+1}\",\n",
        "                        \"content\": doc_info['doc'][:200] + \"...\",\n",
        "                        \"similarity\": f\"{doc_info['similarity']:.3f}\"\n",
        "                    })\n",
        "\n",
        "        # Add user health conditions to context if available\n",
        "        if user_context.get(\"healthConditions\"):\n",
        "            conditions = \", \".join(user_context[\"healthConditions\"])\n",
        "            context = f\"Patient has the following health conditions: {conditions}\\n\\n{context}\"\n",
        "\n",
        "        # Generate AI response using Med42\n",
        "        ai_response = generate_med42_response(query, context, max_tokens=150)\n",
        "\n",
        "        # Format response for the app\n",
        "        response = {\n",
        "            \"response\": ai_response,\n",
        "            \"sources\": sources,\n",
        "            \"mockMode\": False\n",
        "        }\n",
        "\n",
        "        print(f\"Generated response: {ai_response[:100]}...\")\n",
        "        print(f\"Sources count: {len(sources)}\")\n",
        "\n",
        "        return jsonify(response)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in /ask endpoint: {e}\")\n",
        "        return jsonify({\n",
        "            \"response\": \"I apologize, but I'm experiencing technical difficulties. Please try again later.\",\n",
        "            \"sources\": [],\n",
        "            \"mockMode\": True,\n",
        "            \"error\": str(e)\n",
        "        }), 500\n",
        "\n",
        "@app.route('/health', methods=['GET'])\n",
        "def health_check():\n",
        "    return jsonify({\n",
        "        \"status\": \"healthy\",\n",
        "        \"models\": {\n",
        "            \"med42\": \"loaded\",\n",
        "            \"biobert\": \"loaded\"\n",
        "        },\n",
        "        \"documents\": len(docs)\n",
        "    })\n",
        "\n",
        "# Start Flask app in a thread\n",
        "def run_app():\n",
        "    app.run(port=5000, debug=False)\n",
        "\n",
        "# Start the Flask app\n",
        "thread = threading.Thread(target=run_app)\n",
        "thread.daemon = True\n",
        "thread.start()\n",
        "\n",
        "# Setup ngrok\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"üåê Public URL:\", public_url)\n",
        "print(\"ü§ñ Med42 (Llama3-Med42-8B) and BioBERT models loaded and ready!\")\n",
        "print(\"üìö Sample documents embedded:\", len(docs))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import signal\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Kill ngrok\n",
        "ngrok.kill()\n",
        "\n",
        "# Kill the Flask thread by killing the whole Colab process (if needed)\n",
        "os.kill(os.getpid(), signal.SIGKILL)\n",
        "\n",
        "print('Killed')"
      ],
      "metadata": {
        "id": "wdH_5gtxiQ3G"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e17ad857c6884aec994184b135a7c50d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bed7c65e3684fe984468680ae73c8c1",
              "IPY_MODEL_630fae45715d4876a8e331908f6f74da",
              "IPY_MODEL_8109bc2b44d74c05bab4f263cdc027e6"
            ],
            "layout": "IPY_MODEL_b2530948c6e849ee9c372dee5794e282"
          }
        },
        "7bed7c65e3684fe984468680ae73c8c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a8e598407214db2a90c07f8ec7be0f8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_25307efe3d964e76a2abd42b339d0970",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "630fae45715d4876a8e331908f6f74da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74c4c1240380442f903acc60c98b8ca0",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cab90b6c58d74172b80c8313806d8d3f",
            "value": 4
          }
        },
        "8109bc2b44d74c05bab4f263cdc027e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb71bccac6474194bb4718bef0291ab1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_720ce7addcf04943ae30775d46f669e7",
            "value": "‚Äá4/4‚Äá[00:44&lt;00:00,‚Äá11.05s/it]"
          }
        },
        "b2530948c6e849ee9c372dee5794e282": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a8e598407214db2a90c07f8ec7be0f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25307efe3d964e76a2abd42b339d0970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74c4c1240380442f903acc60c98b8ca0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cab90b6c58d74172b80c8313806d8d3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb71bccac6474194bb4718bef0291ab1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "720ce7addcf04943ae30775d46f669e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}