{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# WellnessGrid RAG System - Supabase Edition\n",
        "\n",
        "This notebook demonstrates a complete RAG (Retrieval-Augmented Generation) system for medical questions using:\n",
        "\n",
        "1. ü§ñ **BioGPT** for medical text generation\n",
        "2. üóÑÔ∏è **Supabase + pgvector** for document retrieval\n",
        "3. üåê **Flask API with ngrok** for external access\n",
        "4. üîç **Pre-embedded medical documents** from your database\n",
        "\n",
        "## Features:\n",
        "- **Medical AI Model**: BioGPT for medical text generation\n",
        "- **Vector Search**: Supabase pgvector with existing embeddings\n",
        "- **Flask API**: Compatible with WellnessGrid frontend\n",
        "- **Google Colab**: GPU-accelerated inference\n",
        "- **ngrok**: Public URL for external access\n",
        "\n",
        "## Recent Updates (Fixed):\n",
        "- ‚úÖ **Fixed RPC Function**: Now uses correct `search_embeddings` function\n",
        "- ‚úÖ **Added Embeddings**: Re-added sentence-transformers for query encoding\n",
        "- ‚úÖ **Correct Parameters**: Fixed parameter names and response field mapping\n",
        "- ‚úÖ **Enhanced Testing**: Better error handling and diagnostics\n",
        "\n",
        "## Setup Instructions:\n",
        "1. Run this notebook in Google Colab with GPU enabled\n",
        "2. Execute cells in order to load BioGPT model\n",
        "3. Enter your Supabase credentials and ngrok auth token when prompted\n",
        "4. Use the generated ngrok URL in your WellnessGrid app\n",
        "\n",
        "## Prerequisites:\n",
        "- Supabase database with `medical_documents` and `document_embeddings` tables\n",
        "- Documents embedded using `embed_documents.py` script\n",
        "- RPC function `search_embeddings` deployed in Supabase\n",
        "\n",
        "**‚ö° RAG system using your existing Supabase embeddings**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages for Google Colab\n",
        "%pip install transformers torch sentence-transformers --quiet\n",
        "%pip install flask flask-cors pyngrok --quiet\n",
        "%pip install supabase python-dotenv --quiet\n",
        "%pip install sacremoses --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Any, Optional\n",
        "import torch\n",
        "from getpass import getpass\n",
        "\n",
        "# AI Models\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Supabase\n",
        "from supabase import create_client\n",
        "\n",
        "# Flask API\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "\n",
        "print(\"üì¶ All packages imported successfully!\")\n",
        "print(f\"üïê RAG session started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"üîß Using device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")\n",
        "print(\"ü§ñ Loading BioGPT model for medical text generation...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load BioGPT for medical text generation\n",
        "print(\"üß† Loading BioGPT for medical text generation...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BioGPT\")\n",
        "biogpt_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/BioGPT\",\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "\n",
        "# Move to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "biogpt_model = biogpt_model.to(device)\n",
        "\n",
        "# Set pad token\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "print(f\"‚úÖ BioGPT loaded and moved to {device}\")\n",
        "\n",
        "# Setup Supabase connection\n",
        "print(\"üóÑÔ∏è Setting up Supabase connection...\")\n",
        "print(\"Please enter your Supabase credentials:\")\n",
        "supabase_url = getpass(\"Supabase URL: \")\n",
        "supabase_key = getpass(\"Supabase Service Role Key: \")\n",
        "\n",
        "supabase = create_client(supabase_url, supabase_key)\n",
        "print(\"‚úÖ Supabase client initialized\")\n",
        "\n",
        "# Configuration\n",
        "CONFIG = {\n",
        "    \"top_k\": 5,\n",
        "    \"similarity_threshold\": 0.5,\n",
        "    \"max_context_length\": 2000,\n",
        "    \"max_response_length\": 150,\n",
        "}\n",
        "\n",
        "print(f\"\\n‚öôÔ∏è RAG Configuration:\")\n",
        "print(f\"   üéØ Retrieve top {CONFIG['top_k']} similar documents\")\n",
        "print(f\"   üìä Similarity threshold: {CONFIG['similarity_threshold']}\")\n",
        "print(f\"   üìè Max context length: {CONFIG['max_context_length']} chars\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Supabase document retrieval functions\n",
        "def query_supabase_documents(query: str, top_k: int = None) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Query Supabase for similar documents using vector search\"\"\"\n",
        "    try:\n",
        "        from sentence_transformers import SentenceTransformer\n",
        "        \n",
        "        # Load the same embedding model used for indexing\n",
        "        print(f\"üîç Loading embedding model for query: {query[:50]}...\")\n",
        "        embedding_model = SentenceTransformer('NeuML/pubmedbert-base-embeddings')\n",
        "        \n",
        "        top_k = top_k or CONFIG['top_k']\n",
        "        \n",
        "        # Generate embedding for the query\n",
        "        print(f\"üß† Generating embedding vector...\")\n",
        "        query_embedding = embedding_model.encode([query])[0].tolist()\n",
        "        \n",
        "        # Use the correct RPC function from schema.sql: search_embeddings\n",
        "        print(f\"üîç Searching embeddings with threshold {CONFIG['similarity_threshold']}...\")\n",
        "        result = supabase.rpc('search_embeddings', {\n",
        "            'query_embedding': query_embedding,\n",
        "            'match_threshold': CONFIG['similarity_threshold'],\n",
        "            'match_count': top_k\n",
        "        }).execute()\n",
        "        \n",
        "        if result.data:\n",
        "            documents = []\n",
        "            for i, doc in enumerate(result.data):\n",
        "                documents.append({\n",
        "                    'content': doc.get('chunk_content', ''),  # Correct field name from RPC\n",
        "                    'similarity_score': doc.get('similarity', 0.0),\n",
        "                    'metadata': {\n",
        "                        'title': doc.get('title', 'Medical Document'),\n",
        "                        'source': doc.get('source', 'unknown'),\n",
        "                        'topic': doc.get('topic', 'general'),\n",
        "                        'document_type': doc.get('document_type', 'unknown'),\n",
        "                        'document_id': doc.get('document_id', '')\n",
        "                    },\n",
        "                    'rank': i + 1,\n",
        "                    'doc_id': doc.get('document_id', '')\n",
        "                })\n",
        "            \n",
        "            print(f\"üìä Found {len(documents)} similar documents from Supabase\")\n",
        "            return documents\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è No similar documents found in Supabase\")\n",
        "            return []\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error querying Supabase: {str(e)}\")\n",
        "        # Fallback: try direct table query if RPC function doesn't exist\n",
        "        try:\n",
        "            print(\"üîÑ Trying fallback query method...\")\n",
        "            result = supabase.table('medical_documents').select('*').limit(top_k).execute()\n",
        "            \n",
        "            if result.data:\n",
        "                documents = []\n",
        "                for i, doc in enumerate(result.data[:top_k]):\n",
        "                    documents.append({\n",
        "                        'content': doc.get('content', ''),\n",
        "                        'similarity_score': 0.8,  # Default similarity\n",
        "                        'metadata': {\n",
        "                            'title': doc.get('title', 'Medical Document'),\n",
        "                            'source': doc.get('source', 'unknown'),\n",
        "                            'topic': doc.get('topic', 'general'),\n",
        "                            'document_type': doc.get('document_type', 'unknown'),\n",
        "                            'document_id': doc.get('id', '')\n",
        "                        },\n",
        "                        'rank': i + 1,\n",
        "                        'doc_id': doc.get('id', '')\n",
        "                    })\n",
        "                \n",
        "                print(f\"üìä Fallback: Retrieved {len(documents)} documents from Supabase\")\n",
        "                return documents\n",
        "            \n",
        "        except Exception as fallback_error:\n",
        "            print(f\"‚ùå Fallback query also failed: {str(fallback_error)}\")\n",
        "            return []\n",
        "\n",
        "# Test Supabase connection and RPC functions\n",
        "print(\"üß™ Testing Supabase connection...\")\n",
        "try:\n",
        "    # Test basic connection\n",
        "    test_result = supabase.table('medical_documents').select('count').execute()\n",
        "    doc_count = len(test_result.data) if test_result.data else 0\n",
        "    print(f\"‚úÖ Supabase connected - Found {doc_count} documents in database\")\n",
        "    \n",
        "    # Test RPC function availability\n",
        "    print(\"üß™ Testing RPC functions...\")\n",
        "    try:\n",
        "        stats_result = supabase.rpc('get_document_stats').execute()\n",
        "        if stats_result.data:\n",
        "            print(\"‚úÖ RPC functions working\")\n",
        "            for stat in stats_result.data[:3]:  # Show first 3 document sources\n",
        "                print(f\"   üìÑ {stat['source']}: {stat['count']} documents\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è RPC function exists but returned no data\")\n",
        "    except Exception as rpc_error:\n",
        "        print(f\"‚ö†Ô∏è RPC function test failed: {str(rpc_error)}\")\n",
        "        print(\"   Vector search will use fallback method\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Supabase connection test failed: {str(e)}\")\n",
        "    print(\"   The system will still work but may have limited document retrieval\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_biogpt_response(prompt: str, max_length: int = 150) -> str:\n",
        "    \"\"\"Generate medical response using BioGPT\"\"\"\n",
        "    try:\n",
        "        inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            outputs = biogpt_model.generate(\n",
        "                inputs,\n",
        "                max_length=len(inputs[0]) + max_length,\n",
        "                num_return_sequences=1,\n",
        "                temperature=0.7,\n",
        "                do_sample=True,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id,\n",
        "                no_repeat_ngram_size=2\n",
        "            )\n",
        "        \n",
        "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        \n",
        "        if prompt in response:\n",
        "            response = response.replace(prompt, \"\").strip()\n",
        "        \n",
        "        if not response or len(response) < 10:\n",
        "            response = \"I understand your question about health. Please consult with a healthcare professional for personalized medical advice.\"\n",
        "        \n",
        "        return response\n",
        "    except Exception as e:\n",
        "        return f\"I apologize, but I encountered an error processing your question. Please try rephrasing your question or consult with a healthcare professional.\"\n",
        "\n",
        "class WellnessRAGSystem:\n",
        "    \"\"\"RAG system for medical/wellness queries using Supabase and BioGPT\"\"\"\n",
        "    \n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "    \n",
        "    def retrieve_context(self, query: str) -> Dict[str, Any]:\n",
        "        \"\"\"Retrieve relevant document chunks from Supabase\"\"\"\n",
        "        retrieved_docs = query_supabase_documents(query, self.config['top_k'])\n",
        "        \n",
        "        context_parts = []\n",
        "        total_chars = 0\n",
        "        \n",
        "        for doc in retrieved_docs:\n",
        "            if total_chars + len(doc['content']) <= self.config['max_context_length']:\n",
        "                context_parts.append(f\"Source: {doc['metadata']['source']}\\n{doc['content']}\")\n",
        "                total_chars += len(doc['content'])\n",
        "            else:\n",
        "                break\n",
        "        \n",
        "        context = \"\\n\\n\".join(context_parts)\n",
        "        \n",
        "        return {\n",
        "            'query': query,\n",
        "            'context': context,\n",
        "            'retrieved_documents': retrieved_docs,\n",
        "            'total_documents_found': len(retrieved_docs),\n",
        "            'documents_used': len(retrieved_docs),\n",
        "            'context_length': len(context)\n",
        "        }\n",
        "    \n",
        "    def query(self, question: str) -> Dict[str, Any]:\n",
        "        \"\"\"Complete RAG query: retrieve context and generate response\"\"\"\n",
        "        print(f\"üîç Processing query: {question}\")\n",
        "        \n",
        "        context_result = self.retrieve_context(question)\n",
        "        \n",
        "        print(f\"üìä Found {context_result['total_documents_found']} similar documents\")\n",
        "        print(f\"üìÑ Using {context_result['documents_used']} documents for context\")\n",
        "        \n",
        "        print(\"ü§ñ Generating response using BioGPT...\")\n",
        "        medical_prompt = f\"Medical Question: {question}\\n{context_result['context']}\\nAnswer:\"\n",
        "        generated_response = generate_biogpt_response(medical_prompt, self.config['max_response_length'])\n",
        "        print(\"‚úÖ Response generated successfully\")\n",
        "        \n",
        "        result = {\n",
        "            'query': question,\n",
        "            'response': generated_response,\n",
        "            'sources': [\n",
        "                {\n",
        "                    'title': doc['metadata'].get('title', 'Medical Document'),\n",
        "                    'source': doc['metadata']['source'],\n",
        "                    'topic': doc['metadata']['topic'],\n",
        "                    'similarity': f\"{doc['similarity_score']:.3f}\",\n",
        "                    'rank': doc['rank'],\n",
        "                    'content_preview': doc['content'][:150] + \"...\"\n",
        "                }\n",
        "                for doc in context_result['retrieved_documents']\n",
        "            ],\n",
        "            'metadata': {\n",
        "                'documentsUsed': context_result['documents_used'],\n",
        "                'totalFound': context_result['total_documents_found'],\n",
        "                'contextLength': context_result['context_length'],\n",
        "                'model': 'BioGPT',\n",
        "                'embeddings': 'Supabase pgvector',\n",
        "                'processingTime': datetime.now().isoformat()\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        return result\n",
        "\n",
        "# Initialize the RAG system\n",
        "rag_system = WellnessRAGSystem(config=CONFIG)\n",
        "print(\"‚úÖ WellnessGrid RAG system initialized!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Flask API Setup\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "@app.route('/query', methods=['POST'])\n",
        "def query_docs():\n",
        "    \"\"\"Query similar documents from Supabase\"\"\"\n",
        "    data = request.get_json()\n",
        "    query = data.get(\"query\", \"\")\n",
        "    top_k = data.get(\"top_k\", CONFIG['top_k'])\n",
        "    \n",
        "    if not query:\n",
        "        return jsonify({\"error\": \"Missing 'query' field.\"}), 400\n",
        "\n",
        "    results = query_supabase_documents(query, top_k=top_k)\n",
        "    return jsonify(results)\n",
        "\n",
        "@app.route('/ask', methods=['POST'])\n",
        "def ask_rag():\n",
        "    \"\"\"Main RAG endpoint for WellnessGrid app\"\"\"\n",
        "    try:\n",
        "        data = request.get_json()\n",
        "        question = data.get(\"question\", \"\")\n",
        "        \n",
        "        if not question:\n",
        "            return jsonify({\"error\": \"Missing 'question' field.\"}), 400\n",
        "        \n",
        "        result = rag_system.query(question)\n",
        "        \n",
        "        return jsonify({\n",
        "            \"response\": result['response'],\n",
        "            \"sources\": [\n",
        "                {\n",
        "                    \"title\": source['title'], \n",
        "                    \"content\": source['content_preview'],\n",
        "                    \"similarity\": float(source['similarity'])\n",
        "                }\n",
        "                for source in result['sources']\n",
        "            ],\n",
        "            \"mockMode\": False,\n",
        "            \"metadata\": result['metadata']\n",
        "        })\n",
        "        \n",
        "    except Exception as e:\n",
        "        return jsonify({\n",
        "            \"response\": f\"I apologize, but I encountered an error processing your question: {str(e)}\",\n",
        "            \"sources\": [],\n",
        "            \"mockMode\": True,\n",
        "            \"error\": str(e)\n",
        "        }), 500\n",
        "\n",
        "@app.route('/health', methods=['GET'])\n",
        "def health_check():\n",
        "    \"\"\"Health check endpoint\"\"\"\n",
        "    try:\n",
        "        # Test Supabase connection\n",
        "        test_result = supabase.table('medical_documents').select('count').execute()\n",
        "        doc_count = len(test_result.data) if test_result.data else 0\n",
        "        \n",
        "        return jsonify({\n",
        "            \"status\": \"healthy\",\n",
        "            \"model\": \"BioGPT\",\n",
        "            \"database\": \"Supabase + pgvector\",\n",
        "            \"documents_in_db\": doc_count,\n",
        "            \"rag_system\": \"active\"\n",
        "        })\n",
        "    except Exception as e:\n",
        "        return jsonify({\n",
        "            \"status\": \"partial\",\n",
        "            \"model\": \"BioGPT\", \n",
        "            \"database\": \"Supabase (connection issues)\",\n",
        "            \"documents_in_db\": \"unknown\",\n",
        "            \"rag_system\": \"active\",\n",
        "            \"warning\": str(e)\n",
        "        })\n",
        "\n",
        "print(\"üåê Flask API endpoints configured:\")\n",
        "print(\"  - POST /ask - Main RAG endpoint for WellnessGrid\")\n",
        "print(\"  - GET /health - Health check\")\n",
        "print(\"  - POST /query - Query documents from Supabase\")\n",
        "print(\"‚úÖ Ready to start ngrok tunnel and Flask server\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the RAG system\n",
        "print(\"üß™ Testing RAG system with sample question...\")\n",
        "\n",
        "test_question = \"What are the symptoms of diabetes?\"\n",
        "try:\n",
        "    print(f\"üîç Testing query: {test_question}\")\n",
        "    result = rag_system.query(test_question)\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(f\"‚ùì QUESTION: {result['query']}\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    print(f\"\\nü§ñ AI RESPONSE:\")\n",
        "    print(f\"{result['response']}\")\n",
        "    \n",
        "    print(f\"\\nüìö SOURCES ({result['metadata']['documentsUsed']} documents):\")\n",
        "    if result['sources']:\n",
        "        for i, source in enumerate(result['sources'], 1):\n",
        "            print(f\"   {i}. {source['title']} - {source['source']}\")\n",
        "            print(f\"      üìä Similarity: {source['similarity']}\")\n",
        "            print(f\"      üìÑ Preview: {source['content_preview']}\")\n",
        "            print()\n",
        "    else:\n",
        "        print(\"   ‚ö†Ô∏è No sources found - this could indicate:\")\n",
        "        print(\"   ‚Ä¢ No documents in database yet\")\n",
        "        print(\"   ‚Ä¢ Similarity threshold too high\")\n",
        "        print(\"   ‚Ä¢ RPC function needs adjustment\")\n",
        "    \n",
        "    print(f\"\\nüìä Metadata:\")\n",
        "    print(f\"   üîß Model: {result['metadata']['model']}\")\n",
        "    print(f\"   üíæ Embeddings: {result['metadata']['embeddings']}\")\n",
        "    print(f\"   üìÑ Documents Used: {result['metadata']['documentsUsed']}\")\n",
        "    print(f\"   üéØ Total Found: {result['metadata']['totalFound']}\")\n",
        "    \n",
        "    print(\"‚úÖ RAG system test completed!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è RAG test failed: {str(e)}\")\n",
        "    print(\"   This might be normal if:\")\n",
        "    print(\"   ‚Ä¢ Supabase connection needs adjustment\")\n",
        "    print(\"   ‚Ä¢ No documents have been embedded yet\")\n",
        "    print(\"   ‚Ä¢ RPC function is not deployed\")\n",
        "    print(\"   The Flask server will still start and you can test via the API\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ngrok setup and Flask server startup\n",
        "from pyngrok import ngrok\n",
        "\n",
        "print(\"üîë Please enter your ngrok auth token (get it from https://ngrok.com)\")\n",
        "print(\"   Your token will be hidden for security\")\n",
        "token = getpass(\"Enter ngrok auth token: \")\n",
        "\n",
        "ngrok.set_auth_token(token)\n",
        "print(\"‚úÖ Ngrok token set successfully!\")\n",
        "\n",
        "# Validate setup\n",
        "print(\"üîç Validating setup...\")\n",
        "\n",
        "try:\n",
        "    # Check everything is loaded\n",
        "    assert biogpt_model is not None, \"BioGPT model not loaded\"\n",
        "    assert tokenizer is not None, \"Tokenizer not loaded\"\n",
        "    assert supabase is not None, \"Supabase client not initialized\"\n",
        "    assert rag_system is not None, \"RAG system not initialized\"\n",
        "    \n",
        "    print(f\"‚úÖ BioGPT model: Loaded\")\n",
        "    print(f\"‚úÖ Supabase client: Initialized\")\n",
        "    print(f\"‚úÖ RAG system: Initialized\")\n",
        "    print(f\"‚úÖ Device: {device}\")\n",
        "    \n",
        "    # Test Supabase connection one more time\n",
        "    try:\n",
        "        test_result = supabase.table('medical_documents').select('count').execute()\n",
        "        doc_count = len(test_result.data) if test_result.data else 0\n",
        "        print(f\"‚úÖ Supabase: Connected ({doc_count} documents)\")\n",
        "    except Exception as db_error:\n",
        "        print(f\"‚ö†Ô∏è Supabase: Connection issues ({str(db_error)})\")\n",
        "        print(\"   RAG system will still work but may have limited retrieval\")\n",
        "    \n",
        "    # Start ngrok tunnel\n",
        "    print(\"üåê Starting ngrok tunnel...\")\n",
        "    public_url = ngrok.connect(5000)\n",
        "    print(f\"üåç Public URL: {public_url}\")\n",
        "    print(\"üìã Copy this URL to your WellnessGrid app configuration!\")\n",
        "    \n",
        "    # Start Flask app\n",
        "    print(\"üöÄ Starting Flask app...\")\n",
        "    print(\"üì° Available endpoints:\")\n",
        "    print(\"  - POST /ask - Main RAG endpoint for WellnessGrid\")\n",
        "    print(\"  - GET /health - Health check\")\n",
        "    print(\"  - POST /query - Query documents from Supabase\")\n",
        "    print(\"\\n‚ö†Ô∏è  Keep this cell running to maintain the server!\")\n",
        "    print(\"\\nüéØ Your WellnessGrid RAG system is now live!\")\n",
        "    \n",
        "    app.run(host='0.0.0.0', port=5000, debug=False)\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Setup validation failed: {str(e)}\")\n",
        "    print(\"Please run all previous cells in order before starting the Flask app.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
